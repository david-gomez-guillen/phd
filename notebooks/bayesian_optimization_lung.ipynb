{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Optimization benchmark for cost-effectiveness models (lung model)\n",
    "\n",
    "Models evaluated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T05:18:42.084062Z",
     "start_time": "2022-02-27T05:18:39.313247Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import pi, cos, sqrt\n",
    "from timeit import default_timer as timer\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import pandas2ri\n",
    "\n",
    "r = ro.r\n",
    "r.setwd(globals()['_dh'][0] + '/../models/lung/3_ModelAECC_Gerard/ModelLC/Git_LC')\n",
    "r.source('calibration_wrapper.R')\n",
    "simulate_func = ro.globalenv['distance.function']\n",
    "\n",
    "initial_guess = [\n",
    "    1.213941e-06, 6.545872e-01, 2.246275e-01, 5.963744e-01, 2.394308e-02, 3.106926e-02, 2.794314e-02, 1.087255e-05, 6.844754e-01, \n",
    "    1.051884e-01, 7.424919e-01, 1.887970e-02, 2.471663e-02, 2.791269e-02, 3.205524e-05, 2.313676e-01, 3.555522e-02, 8.856038e-01, \n",
    "    1.132692e-02, 2.438057e-02, 1.744913e-02, 3.294341e-05, 3.026535e-01, 1.621603e-01, 6.240864e-01, 6.033806e-03, 3.053075e-02, \n",
    "    2.260926e-02, 4.296202e-05, 4.960837e-01, 1.606893e-01, 9.363777e-01, 1.769338e-02, 1.353436e-03, 2.057389e-02, 4.512876e-05, \n",
    "    1.024800e-01, 6.893908e-02, 1.601334e-01, 1.034956e-02, 1.300131e-02, 2.715497e-02, 3.758481e-05, 1.354800e-01, 1.826121e-02, \n",
    "    6.013894e-01, 2.711442e-02, 3.465066e-03, 2.510431e-02, 5.687846e-05, 3.202555e-02, 8.399107e-02, 8.905349e-01, 1.125023e-03, \n",
    "    3.516895e-02, 3.145581e-02, 3.695752e-05, 9.087717e-01, 5.573168e-03, 7.610368e-01, 4.831828e-02, 1.839338e-02, 4.312801e-02\n",
    "]\n",
    "\n",
    "functions = [\n",
    "    {\n",
    "        'function': simulate_func,\n",
    "        'initial_guesses': [initial_guess],\n",
    "        'bounds': [(p*.8, min(p*1.2, 1)) for p in initial_guess],\n",
    "    }, \n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Classical optimization\n",
    "\n",
    "Optimization methods used (with different initial guesses tested):\n",
    "\n",
    "- Nelder-Mead\n",
    "- BFGS\n",
    "- L-BFGS-B\n",
    "\n",
    "Currently disabled due to excessive computation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T05:12:58.212849Z",
     "start_time": "2022-02-27T05:11:06.688779Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "methods = ['Nelder-Mead', 'BFGS', 'L-BFGS-B']\n",
    "\n",
    "\n",
    "params_set = itertools.product(functions,            # Objective functions\n",
    "                               methods)              # Optimization methods\n",
    "\n",
    "def classical_function_wrapper(func):\n",
    "    def wrapper(X):\n",
    "        X2 = ro.vectors.FloatVector(X)\n",
    "        result = func(X2)\n",
    "        print(result.rx2(1)[0])\n",
    "        return result.rx2(1)[0]\n",
    "    return wrapper\n",
    "\n",
    "results_df = pd.DataFrame()\n",
    "for f, method in params_set:\n",
    "    for initial_guess in f['initial_guesses']:\n",
    "        function = f['function']\n",
    "        start = timer()\n",
    "        result = minimize(classical_function_wrapper(function), initial_guess, method=method)\n",
    "        elapsed_time = timer() - start\n",
    "        x = result['x']\n",
    "        fun = result['fun']\n",
    "        print(result)\n",
    "        error = opt_error(x, f['minima'])\n",
    "        success = result['success']\n",
    "        nfev = result['nfev']\n",
    "        nit = result['nit']\n",
    "        results_df = results_df.append(\n",
    "            {\n",
    "                'function': function.__name__,\n",
    "                'method': method,\n",
    "                'initial_guess': initial_guess,\n",
    "                'time': elapsed_time,\n",
    "                'solution': x,\n",
    "                'error': error,\n",
    "                'n_samples': None,\n",
    "                'iterations': nit,\n",
    "                'evaluations': nfev,\n",
    "                'prior_width': None,\n",
    "                'success': success,\n",
    "            }, ignore_index=True\n",
    "        )\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian optimization\n",
    "\n",
    "- Surrogate model used: Gaussian process\n",
    "- Prior for the optimum: Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T13:24:43.344977Z",
     "start_time": "2022-02-27T05:18:44.138255Z"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "import os\n",
    "from functools import reduce\n",
    "from contextlib import redirect_stdout\n",
    "from hypermapper import optimizer\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "N_CORES = 1\n",
    "N_PRIOR_BINS = 10\n",
    "DEBUG = True\n",
    "\n",
    "def bo_function_wrapper(func):\n",
    "    def wrapper(X):\n",
    "        X2 = [X['x{}'.format(i+1)] for i in range(len(X))]\n",
    "        X2 = ro.vectors.FloatVector(X2)\n",
    "        result = func(X2)\n",
    "        print(result.rx2(1)[0])\n",
    "        return result.rx2(1)[0]\n",
    "    return wrapper\n",
    "\n",
    "'''def classical_function_wrapper(func):\n",
    "    def wrapper(X):\n",
    "        X2 = ro.vectors.FloatVector(X)\n",
    "        result = func(X2)\n",
    "        print(result.rx2(1)[0])\n",
    "        return result.rx2(1)[0]\n",
    "    return wrapper'''\n",
    "            \n",
    "def bo_optimization(f, model, n_samples, optim_iters, prior_width, experiment_num):\n",
    "    example_scenario = {\n",
    "        \"application_name\": \"bo_lung_{}\".format(experiment_num),\n",
    "        \"design_of_experiment\": {\n",
    "            \"doe_type\": \"random sampling\",\n",
    "            \"number_of_samples\": n_samples\n",
    "        },\n",
    "        \"optimization_objectives\": [\"Value\"],\n",
    "        \"optimization_iterations\": optim_iters,\n",
    "        \"models\": {\n",
    "            \"model\": model\n",
    "        },\n",
    "        \"input_parameters\" : {\n",
    "        },\n",
    "        #\"print_posterior_best\": True,\n",
    "        #\"print_best\": True,\n",
    "    }\n",
    "    \n",
    "    for i, bounds in enumerate(f['bounds']):            \n",
    "        example_scenario['input_parameters']['x{}'.format(i+1)] = {\n",
    "            'parameter_type': 'real',\n",
    "            'values': bounds,\n",
    "        }\n",
    "        if prior_width != -1:\n",
    "            example_scenario['input_parameters']['x{}'.format(i+1)]['prior'] = 'gaussian'\n",
    "            \n",
    "    scenario_file_path = \"bo_optimization_scenario_{}.json\".format(experiment_num)\n",
    "    with open(scenario_file_path, \"w\") as scenario_file:\n",
    "        json.dump(example_scenario, scenario_file, indent=4)\n",
    "\n",
    "    stdout = sys.stdout # Jupyter uses a special stdout and HyperMapper logging overwrites it. Save stdout to restore later\n",
    "    start = timer()\n",
    "    with open(os.devnull, 'w') as devnull:\n",
    "        if DEBUG:\n",
    "            optimizer.optimize(scenario_file_path, bo_function_wrapper(f['function']))\n",
    "        else:\n",
    "            with redirect_stdout(devnull):\n",
    "                optimizer.optimize(scenario_file_path, bo_function_wrapper(f['function']))\n",
    "    elapsed_time = timer() - start\n",
    "    sys.stdout = stdout\n",
    "    df = pd.read_csv('bo_lung_{}_output_samples.csv'.format(experiment_num))\n",
    "    best_found = df.sort_values('Value').iloc[1,:]\n",
    "\n",
    "    x = list(best_found[0:len(f['bounds'])])\n",
    "    print(df)\n",
    "\n",
    "    print('Test {} done.'.format(experiment_num))\n",
    "    \n",
    "    return {\n",
    "            'function': 'lung_model',\n",
    "            'method': 'BO',\n",
    "            'initial_guess': None,\n",
    "            'time': elapsed_time,\n",
    "            'solution': x,\n",
    "            'error': error,\n",
    "            'n_samples': n_samples,\n",
    "            'iterations': None,\n",
    "            'evaluations': optim_iters,\n",
    "            'prior_width': prior_width,\n",
    "            'success': 1,\n",
    "    }\n",
    "       \n",
    "pars = [\n",
    "    functions,            # Objective functions\n",
    "    ['gaussian_process'], # Model\n",
    "    [50],                  # Number of samples\n",
    "    [30],                 # Optimization iterations\n",
    "    [1]                  # Use prior?\n",
    "]\n",
    "params_set = itertools.product(*pars)           # Use prior?\n",
    "num_combinations = reduce(lambda x,y:x*y, [len(p) for p in pars])\n",
    "\n",
    "print('{} tests to perform...'.format(num_combinations))\n",
    "with ProcessPoolExecutor(N_CORES) as executor:\n",
    "    futures = []\n",
    "    for i, (f, model, n_samples, optim_iters, prior_width) in enumerate(params_set):\n",
    "        futures.append(executor.submit(bo_optimization, f, model, n_samples, optim_iters, prior_width, i))\n",
    "        \n",
    "    start = timer()\n",
    "    results = [f.result() for f in futures]\n",
    "    print('Total experiment time: {0:.2f} min'.format((timer() - start)/60))\n",
    "    bo_results_df = pd.DataFrame(results)       \n",
    "        \n",
    "bo_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = results_df.append(bo_results_df)\n",
    "df.to_csv('bo_lung_optimization_comparison.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of BO parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "df = pd.read_csv('bo_lung_optimization_comparison.csv')\n",
    "bo_df = df[df.method.eq('BO')]\n",
    "\n",
    "bo_df.boxplot('time', by='prior_width')\n",
    "bo_df.boxplot('error', by='prior_width')\n",
    "bo_df.boxplot('error', by='n_samples')\n",
    "bo_df.boxplot('error', by='evaluations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of branin function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_branin = df[df.function.eq('branin')]\n",
    "df_branin.boxplot('time', by='method')\n",
    "df_branin.boxplot('evaluations', by='method')\n",
    "df_branin.boxplot('error', by='method')\n",
    "df_branin.boxplot('error', by='n_samples')\n",
    "df_branin[df_branin.method.eq('BO')].boxplot('error', by='evaluations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Comparison of rosenbrock function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rosenbrock = df[df.function.eq('rosenbrock')]\n",
    "df_rosenbrock.boxplot('time', by='method')\n",
    "df_rosenbrock.boxplot('evaluations', by='method')\n",
    "df_rosenbrock.boxplot('error', by='method')\n",
    "df_rosenbrock.boxplot('error', by='n_samples')\n",
    "df_rosenbrock[df_rosenbrock.method.eq('BO')].boxplot('error', by='evaluations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Comparison of rastrigin function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rastrigin = df[df.function.eq('rastrigin')]\n",
    "df_rastrigin.boxplot('time', by='method')\n",
    "df_rastrigin.boxplot('evaluations', by='method')\n",
    "df_rastrigin.boxplot('error', by='method')\n",
    "df_rastrigin.boxplot('error', by='n_samples')\n",
    "df_rastrigin[df_rastrigin.method.eq('BO')].boxplot('error', by='evaluations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
