\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{drummond}
\citation{levin}
\newlabel{A}{{a}{}{}{address.1}{}}
\newlabel{B}{{b}{}{}{address.2}{}}
\newlabel{C}{{c}{}{}{address.3}{}}
\newlabel{D}{{d}{}{}{address.4}{}}
\global\@namedef{n@author@}{4}
\citation{applied_he}
\citation{qalys}
\citation{drummond}
\newlabel{fig:lung_model}{{1}{}{Lung cancer markov model state diagram}{figure.1}{}}
\newlabel{eq:icer}{{1}{}{Introduction}{equation.1}{}}
\citation{gaussian-processes}
\citation{kernel-composition}
\citation{curse-dimensionality}
\citation{gp-high-dim}
\citation{gp-high-dim2}
\citation{gp-additive}
\citation{gp-additive-orthogonal}
\citation{gp-additive-orthogonal}
\newlabel{eq:predictive_posterior}{{2}{}{Gaussian Processes}{equation.2}{}}
\newlabel{eq:additive-orthogonal}{{3}{}{Gaussian Processes}{equation.3}{}}
\citation{lung-model}
\citation{nelder-mead}
\citation{simulated-annealing}
\citation{pso}
\newlabel{eq:expected-improvement}{{4}{}{Optimization Methods}{equation.4}{}}
\newlabel{fig:sim_times}{{2}{}{Total calibration time in log scale against model simulation time required to attain similar levels of error. The bottom left figure shows the exponential trend (in log scale) in the necessary simulation time before the bayesian method becomes the fastest method, as a function of the number of parameters. The bottom right figure is a zoomed-in plot of the same figure removing the log scale}{figure.2}{}}
\newlabel{fig:method_comparison}{{3}{}{Time series of the lung cancer model calibration error (using 1 age group). The error is plotted against the number of evaluations by method}{figure.3}{}}
\citation{acquisition-functions}
\newlabel{fig:results_oak}{{4}{}{Time series of the median BO error with its interquartile range as the shaded area. We used three different kernels: the SE kernel (blue), the univariate SE kernel using only the most significant variable (green) and the OAK kernel under a normality assumption for the inputs (red)}{figure.4}{}}
\citation{gp-additive-orthogonal}
\citation{gp-constraints}
\citation{gp-batch}
\citation{gp-parallel-acq-func}
\citation{gp-gpu}
\bibcite{drummond}{1}
\bibcite{levin}{2}
\bibcite{applied_he}{3}
\bibcite{qalys}{4}
\bibcite{bayesian-opt}{5}
\bibcite{gaussian-processes}{6}
\bibcite{kernel-composition}{7}
\bibcite{curse-dimensionality}{8}
\bibcite{gp-additive}{9}
\bibcite{acquisition-functions}{10}
\bibcite{gp-additive-orthogonal}{11}
\bibcite{gp-high-dim}{12}
\bibcite{gp-high-dim2}{13}
\bibcite{lung-model}{14}
\bibcite{nelder-mead}{15}
\bibcite{simulated-annealing}{16}
\bibcite{pso}{17}
\bibcite{gp-constraints}{18}
\bibcite{gp-batch}{19}
\bibcite{gp-parallel-acq-func}{20}
\bibcite{gp-gpu}{21}
\global\@namedef{@lastpage}{10}
\gdef \@abspage@last{10}
